{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\n\n#Plotting Libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\n\n#Memory management \nimport gc\nimport random\nimport time\nimport xgboost as xgb\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler    \nscaler = StandardScaler()\nminmax = MinMaxScaler()\n\n\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\ntrain_file = \"/kaggle/input/santander-pr/train.csv\"\ntest_file = \"/kaggle/input/santander-pr/test.csv\"\n\ntargetcols = [\"ind_ahor_fin_ult1\",\"ind_aval_fin_ult1\",\"ind_cco_fin_ult1\",\"ind_cder_fin_ult1\",\"ind_cno_fin_ult1\",\"ind_ctju_fin_ult1\",\"ind_ctma_fin_ult1\",\n              \"ind_ctop_fin_ult1\",\"ind_ctpp_fin_ult1\",\"ind_deco_fin_ult1\",\"ind_deme_fin_ult1\",\"ind_dela_fin_ult1\", \"ind_ecue_fin_ult1\",\"ind_fond_fin_ult1\",\n              \"ind_hip_fin_ult1\", \"ind_plan_fin_ult1\",\"ind_pres_fin_ult1\",\"ind_reca_fin_ult1\",\"ind_tjcr_fin_ult1\",\"ind_valo_fin_ult1\",\"ind_viv_fin_ult1\",\n              \"ind_nomina_ult1\",\"ind_nom_pens_ult1\",\"ind_recibo_ult1\"]\n\ndtype_list = {'ind_cco_fin_ult1': 'uint8',\n              'ind_deme_fin_ult1': 'uint8',\n              'ind_aval_fin_ult1': 'uint8',\n              'ind_valo_fin_ult1': 'uint8',\n              'ind_reca_fin_ult1': 'uint8',\n              'ind_ctju_fin_ult1': 'uint8',\n              'ind_cder_fin_ult1': 'uint8', \n              'ind_plan_fin_ult1': 'uint8',\n              'ind_fond_fin_ult1': 'uint8', \n              'ind_hip_fin_ult1': 'uint8',\n              'ind_pres_fin_ult1': 'uint8', \n              'ind_nomina_ult1': 'float64', \n              'ind_cno_fin_ult1': 'uint8',\n              'ind_ctpp_fin_ult1': 'uint8',\n              'ind_ahor_fin_ult1': 'uint8',\n              'ind_dela_fin_ult1': 'uint8',\n              'ind_ecue_fin_ult1': 'uint8',\n              'ind_nom_pens_ult1': 'float64',\n              'ind_recibo_ult1': 'uint8',\n              'ind_deco_fin_ult1': 'uint8',\n              'ind_tjcr_fin_ult1': 'uint8', \n              'ind_ctop_fin_ult1': 'uint8',\n              'ind_viv_fin_ult1': 'uint8',\n              'ind_ctma_fin_ult1': 'uint8',\n             'ncodpers' : 'uint32'}  \n\n# ['fecha_alta','canal_entrada']\n\nfeature_cols = ['ncodpers','fecha_dato','age','renta','nomprov', 'ind_nuevo', \n               'segmento', 'ind_actividad_cliente', 'pais_residencia', 'ind_empleado', \n                'sexo', 'tiprel_1mes', 'indrel_1mes', 'antiguedad',  'indrel', 'indext', 'indresi', 'indfall', 'canal_entrada']\n\nmapping_dict = {\n'pais_residencia' : {'LV': 102, 'BE': 12, 'BG': 50, 'BA': 61, 'BM': 117, 'BO': 62, 'JP': 82, 'JM': 116, 'BR': 17, 'BY': 64, 'BZ': 113, 'RU': 43, 'RS': 89, 'RO': 41, 'GW': 99, 'GT': 44, 'GR': 39, 'GQ': 73, 'GE': 78, 'GB': 9, 'GA': 45, 'GN': 98, 'GM': 110, 'GI': 96, 'GH': 88, 'OM': 100, 'HR': 67, 'HU': 106, 'HK': 34, 'HN': 22, 'AD': 35, 'PR': 40, 'PT': 26, 'PY': 51, 'PA': 60, 'PE': 20, 'PK': 84, 'PH': 91, 'PL': 30, 'EE': 52, 'EG': 74, 'ZA': 75, 'EC': 19, 'AL': 25, 'VN': 90, 'ET': 54, 'ZW': 114, 'ES': 0, 'MD': 68, 'UY': 77, 'MM': 94, 'ML': 104, 'US': 15, 'MT': 118, 'MR': 48, 'UA': 49, 'MX': 16, 'IL': 42, 'FR': 8, 'MA': 38, 'FI': 23, 'NI': 33, 'NL': 7, 'NO': 46, 'NG': 83, 'NZ': 93, 'CI': 57, 'CH': 3, 'CO': 21, 'CN': 28, 'CM': 55, 'CL': 4, 'CA': 2, 'CG': 101, 'CF': 109, 'CD': 112, 'CZ': 36, 'CR': 32, 'CU': 72, 'KE': 65, 'KH': 95, 'SV': 53, 'SK': 69, 'KR': 87, 'KW': 92, 'SN': 47, 'SL': 97, 'KZ': 111, 'SA': 56, 'SG': 66, 'SE': 24, 'DO': 11, 'DJ': 115, 'DK': 76, 'DE': 10, 'DZ': 80, 'MK': 105, -99: 1, 'LB': 81, 'TW': 29, 'TR': 70, 'TN': 85, 'LT': 103, 'LU': 59, 'TH': 79, 'TG': 86, 'LY': 108, 'AE': 37, 'VE': 14, 'IS': 107, 'IT': 18, 'AO': 71, 'AR': 13, 'AU': 63, 'AT': 6, 'IN': 31, 'IE': 5, 'QA': 58, 'MZ': 27},\n'canal_entrada' : {'013': 49, 'KHP': 160, 'KHQ': 157, 'KHR': 161, 'KHS': 162, 'KHK': 10, 'KHL': 0, 'KHM': 12, 'KHN': 21, 'KHO': 13, 'KHA': 22, 'KHC': 9, 'KHD': 2, 'KHE': 1, 'KHF': 19, '025': 159, 'KAC': 57, 'KAB': 28, 'KAA': 39, 'KAG': 26, 'KAF': 23, 'KAE': 30, 'KAD': 16, 'KAK': 51, 'KAJ': 41, 'KAI': 35, 'KAH': 31, 'KAO': 94, 'KAN': 110, 'KAM': 107, 'KAL': 74, 'KAS': 70, 'KAR': 32, 'KAQ': 37, 'KAP': 46, 'KAW': 76, 'KAV': 139, 'KAU': 142, 'KAT': 5, 'KAZ': 7, 'KAY': 54, 'KBJ': 133, 'KBH': 90, 'KBN': 122, 'KBO': 64, 'KBL': 88, 'KBM': 135, 'KBB': 131, 'KBF': 102, 'KBG': 17, 'KBD': 109, 'KBE': 119, 'KBZ': 67, 'KBX': 116, 'KBY': 111, 'KBR': 101, 'KBS': 118, 'KBP': 121, 'KBQ': 62, 'KBV': 100, 'KBW': 114, 'KBU': 55, 'KCE': 86, 'KCD': 85, 'KCG': 59, 'KCF': 105, 'KCA': 73, 'KCC': 29, 'KCB': 78, 'KCM': 82, 'KCL': 53, 'KCO': 104, 'KCN': 81, 'KCI': 65, 'KCH': 84, 'KCK': 52, 'KCJ': 156, 'KCU': 115, 'KCT': 112, 'KCV': 106, 'KCQ': 154, 'KCP': 129, 'KCS': 77, 'KCR': 153, 'KCX': 120, 'RED': 8, 'KDL': 158, 'KDM': 130, 'KDN': 151, 'KDO': 60, 'KDH': 14, 'KDI': 150, 'KDD': 113, 'KDE': 47, 'KDF': 127, 'KDG': 126, 'KDA': 63, 'KDB': 117, 'KDC': 75, 'KDX': 69, 'KDY': 61, 'KDZ': 99, 'KDT': 58, 'KDU': 79, 'KDV': 91, 'KDW': 132, 'KDP': 103, 'KDQ': 80, 'KDR': 56, 'KDS': 124, 'K00': 50, 'KEO': 96, 'KEN': 137, 'KEM': 155, 'KEL': 125, 'KEK': 145, 'KEJ': 95, 'KEI': 97, 'KEH': 15, 'KEG': 136, 'KEF': 128, 'KEE': 152, 'KED': 143, 'KEC': 66, 'KEB': 123, 'KEA': 89, 'KEZ': 108, 'KEY': 93, 'KEW': 98, 'KEV': 87, 'KEU': 72, 'KES': 68, 'KEQ': 138, -99: 6, 'KFV': 48, 'KFT': 92, 'KFU': 36, 'KFR': 144, 'KFS': 38, 'KFP': 40, 'KFF': 45, 'KFG': 27, 'KFD': 25, 'KFE': 148, 'KFB': 146, 'KFC': 4, 'KFA': 3, 'KFN': 42, 'KFL': 34, 'KFM': 141, 'KFJ': 33, 'KFK': 20, 'KFH': 140, 'KFI': 134, '007': 71, '004': 83, 'KGU': 149, 'KGW': 147, 'KGV': 43, 'KGY': 44, 'KGX': 24, 'KGC': 18, 'KGN': 11}\n}","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Pyramid\n\n- ~~Renta, Nomprov~~  : 0.02678\n- ~~Renta, Nomprov, ind_nuevo~~  : 0.02671\n- Renta, Nomprov, ind_nuevo, segmento\n- renta, nomprov, ind_nuevo, segmento, ind_actividad_cliente\n- renta, nomprov, ind_nuevo, segmento, ind_actividad_cliente, pais_residencia\n- renta, nomprov, ind_nuevo, segmento, ind_actividad_cliente, pais_residencia, ind_empleado\n\n\n- renta, nomprov, ind_nuevo, segmento, ind_actividad_cliente, pais_residencia, ind_empleado, sexo\n- renta, nomprov, ind_nuevo, segmento, ind_actividad_cliente, pais_residencia, ind_empleado, sexo, tiprel_1mes\n\n* renta, nomprov, ind_nuevo, segmento, ind_actividad_cliente, pais_residencia, ind_empleado, sexo, tiprel_1mes, indrel_1mes\n\n- ~~renta, nomprov, ind_nuevo, segmento, ind_actividad_cliente, pais_residencia, ind_empleado, sexo, tiprel_1mes, indrel_1mes, antiguedad~~ : 0.02773\n- renta, nomprov, ind_nuevo, segmento, ind_actividad_cliente, pais_residencia, ind_empleado, sexo, tiprel_1mes, indrel_1mes, antiguedad, indrel\n\n\n\n* ~~renta, nomprov, ind_nuevo, segmento, ind_actividad_cliente, pais_residencia, ind_empleado, sexo, tiprel_1mes, indrel_1mes, antiguedad, indrel, indext~~ : 0.02779\n\n\n\n- renta, nomprov, ind_nuevo, segmento, ind_actividad_cliente, pais_residencia, ind_empleado, sexo, tiprel_1mes, indrel_1mes, antiguedad, indrel, indext, indresi\n- renta, nomprov, ind_nuevo, segmento, ind_actividad_cliente, pais_residencia, ind_empleado, sexo, tiprel_1mes, indrel_1mes, antiguedad, indrel, indext, indresi, indfall\n- ~~renta, nomprov, ind_nuevo, segmento, ind_actividad_cliente, pais_residencia, ind_empleado, sexo, tiprel_1mes, indrel_1mes, antiguedad, indrel, indext, indresi, indfall, canal_entrada~~ : 0.02803(Normal logistic)\n- renta, nomprov, ind_nuevo, segmento, ind_actividad_cliente, pais_residencia, ind_empleado, sexo, tiprel_1mes, indrel_1mes, antiguedad, indrel, indext, indresi, indfall, canal_entrada, fecha_alta ","metadata":{}},{"cell_type":"markdown","source":"## Modification Functions\n### Helper Function","metadata":{}},{"cell_type":"code","source":"def string_num_age(x):\n    if(type(x) == str and x != ' NA'):\n        x = int(x)\n    elif( x == ' NA'):\n        x = np.nan\n    return x\n\ndef string_num_senior(x):\n    if(type(x) == str and x != '     NA'):\n        x = int(x)\n    elif( x == '     NA'):\n        x = np.nan\n    return x\n\ndef string_num_primary(x):\n    if(type(x) == str and x!= np.nan and x!='P'):\n        x = float(x)\n    elif(type(x) == float and math.isnan(x)==False):\n        x = int(x)\n    elif(x == 'P'):\n        x = 2.5\n    return x\n\ndef modify_age(train, test):\n    print(\"Modifying...age\")\n    temp_train = train.copy()\n    temp_test = test.copy()\n    temp_train.age = temp_train.age.apply(lambda x: string_num_age(x))\n    temp_train = temp_train.loc[temp_train.age.isnull()==False]\n    temp_train.age = np.where(temp_train.age < 14, 14, temp_train.age)\n    temp_train.age = np.where(temp_train.age > 90, 90, temp_train.age)\n    temp_test.age = np.where(temp_test.age < 14, 14, temp_test.age)\n    temp_test.age = np.where(temp_test.age > 90, 90, temp_test.age)\n\n    temp_train.age = minmax.fit_transform(np.array(temp_train.age).reshape(-1,1))\n    temp_test.age = minmax.fit_transform(np.array(temp_test.age).reshape(-1,1))\n    \n    return temp_train, temp_test\n\ndef modify_renta(train, test):\n    temp_train = train.copy()\n    temp_test = test.copy()\n\n    temp_train.age = temp_train.age.apply(lambda x: string_num_age(x))\n    temp_train = temp_train.loc[temp_train.age.isnull()==False]\n    \n    temp_train.nomprov = temp_train.nomprov.fillna(temp_train.nomprov.mode()[0])\n    temp_train.nomprov = temp_train.nomprov.apply(lambda x: nom_mod(x))\n\n    print('Modifying train...renta')\n    province = temp_train.nomprov.unique()\n#     median = np.zeros((len(province),2))  ## Shape is length(nomprov) x length(ind_actividad_cliente)\n\n#     for i in range(len(province)):\n#         for j in [0,1]:\n#             median[i][j] = temp_train[(temp_train[\"nomprov\"]==province[i]) & temp_train[\"ind_actividad_cliente\"]==j]['renta'].median()\n#     print('Train Medians found ->')\n#     print(median)\n\n#     for i in range(len(province)):\n#         for j in [0,1]:\n#             temp_train.renta = np.where((temp_train.nomprov == province[i]) & (temp_train.ind_actividad_cliente == j) & (temp_train.renta.isnull()==True), median[i][j], temp_train.renta)\n\n#     del median\n    median = np.zeros((len(province),1))\n    for i in range(len(province)):\n        median[i] = temp_train[(temp_train[\"nomprov\"]==province[i])]['renta'].median()\n    print('Train Medians found ->')\n    print(median)\n\n    for i in range(len(province)):\n        temp_train.renta = np.where((temp_train.nomprov == province[i]) & (temp_train.renta.isnull()==True), median[i], temp_train.renta)\n\n    del median\n    \n    temp_test.age = temp_test.age.apply(lambda x: string_num_age(x))\n    temp_test = temp_test.loc[temp_test.age.isnull()==False]\n    \n    temp_test.nomprov = temp_test.nomprov.fillna(temp_test.nomprov.mode()[0])\n    temp_test.nomprov = temp_test.nomprov.apply(lambda x: nom_mod(x))\n    \n    print('Modifying test...renta')\n    province = temp_test.nomprov.unique()\n    median = np.zeros((len(province),1))\n    for i in range(len(province)):\n        median[i] = temp_test[(temp_test[\"nomprov\"]==province[i])]['renta'].median()\n    print('Test Medians found ->')\n    print(median)\n\n    for i in range(len(province)):\n        temp_test.renta = np.where((temp_test.nomprov == province[i]) & (temp_test.renta.isnull()==True), median[i], temp_test.renta)\n\n    del median\n    \n    temp_train.renta = scaler.fit_transform(np.array(temp_train.loc[:,'renta']).reshape(-1,1))\n    temp_test.renta = scaler.fit_transform(np.array(temp_test.loc[:,'renta']).reshape(-1,1))\n    return temp_train, temp_test\n\ndef modify_segmento(train, test):\n    print(\"Modifying....segmento\")\n    temp_train = train.copy()\n    temp_test = test.copy()\n    temp_train.segmento = temp_train.segmento.fillna(temp_train.segmento.mode()[0])\n    temp_test.segmento = temp_test.segmento.fillna(temp_test.segmento.mode()[0])\n    return temp_train, temp_test\n\ndef modify_sexo(train, test):\n    print(\"Modifying....sexo\")\n    temp_train = train.copy()\n    temp_test = test.copy()\n    temp_train.sexo = temp_train.sexo.fillna(value=temp_train.sexo.mode()[0])\n    temp_test.sexo = temp_test.sexo.fillna(value=temp_test.sexo.mode()[0])\n    return temp_train, temp_test\n\ndef modify_antiguedad(train, test):\n    print(\"Modifying....antiguedad\")\n    temp_train = train.copy()\n    temp_test = test.copy()\n    temp_train.antiguedad = temp_train.antiguedad.apply(lambda x: string_num_senior(x))\n    temp_test.antiguedad = temp_test.antiguedad.apply(lambda x: string_num_senior(x))\n    \n    temp_train.antiguedad = temp_train.antiguedad.fillna(value=-999999)\n    temp_test.antiguedad = temp_test.antiguedad.fillna(value=-999999)\n    temp_train.antiguedad = np.where(temp_train.antiguedad==-999999,-1,temp_train.antiguedad)\n    temp_test.antiguedad = np.where(temp_test.antiguedad==-999999,-1,temp_test.antiguedad)\n    temp_train.antiguedad = minmax.fit_transform(np.array(temp_train.loc[:,'antiguedad']).reshape(-1,1))\n    temp_test.antiguedad = minmax.fit_transform(np.array(temp_test.loc[:,'antiguedad']).reshape(-1,1))\n    temp_train.select_dtypes(include=['int']).apply(pd.to_numeric,downcast='signed')\n    temp_train.select_dtypes(include=['float']).apply(pd.to_numeric,downcast='signed')\n    temp_test.select_dtypes(include=['int']).apply(pd.to_numeric,downcast='signed')\n    temp_test.select_dtypes(include=['float']).apply(pd.to_numeric,downcast='signed')\n    return temp_train, temp_test\n\ndef modify_fecha_dato(train, test):\n    print(\"Modifying....fecha_dato\")\n    temp_train = train.copy()\n    temp_test = test.copy()\n    temp_train.age = temp_train.age.apply(lambda x: string_num_age(x))\n    temp_test.age = temp_test.age.apply(lambda x: string_num_age(x))\n    temp_test = temp_test.loc[temp_test.age.isnull()==False]\n    temp_train = temp_train.loc[temp_train.age.isnull()==False]\n    temp_train.fecha_dato = temp_train['fecha_dato'].apply(lambda x: 100*x.year + x.month)\n    temp_test.fecha_dato = temp_test['fecha_dato'].apply(lambda x: 100*x.year + x.month)\n    return temp_train, temp_test\n\ndef modify_fecha_alta(train, test):\n    print(\"Modifying....fecha_alta\")\n    temp_train = train.copy()\n    temp_test = test.copy()\n    temp_train.age = temp_train.age.apply(lambda x: string_num_age(x))\n    temp_test.age = temp_test.age.apply(lambda x: string_num_age(x))\n    temp_test = temp_test.loc[temp_test.age.isnull()==False]\n    temp_train = temp_train.loc[temp_train.age.isnull()==False]\n    temp_train.fecha_alta = temp_train['fecha_alta'].apply(lambda x: 100*x.year + x.month)\n    temp_test.fecha_alta = temp_test['fecha_alta'].apply(lambda x: 100*x.year + x.month)\n    return temp_train, temp_test\n\ndef modify_indrel_1mes(train, test):\n    print(\"Modifying...indrel_1mes\")\n    temp_train = train.copy()\n    temp_test = test.copy()\n    temp_train.indrel_1mes = temp_train.indrel_1mes.apply(lambda x: string_num_primary(x))\n    temp_test.indrel_1mes = temp_test.indrel_1mes.apply(lambda x: string_num_primary(x))\n    temp_train.indrel_1mes = temp_train.indrel_1mes.fillna(temp_train.indrel_1mes.median())\n    temp_test.indrel_1mes = temp_test.indrel_1mes.fillna(temp_test.indrel_1mes.median())\n    return temp_train, temp_test\n\ndef pais_mod(x):\n    pais = ['ES','FR','AR','DE','GB','US','CO','IT','RO','MX']\n    if( x not in pais):\n        x = 'Outside'\n    return x\n    \ndef modify_pais_residencia(train, test):\n    temp_train = train.copy()\n    temp_test = test.copy()\n    temp_train.pais_residencia = temp_train.pais_residencia.apply(lambda x: pais_mod(x))\n    temp_test.pais_residencia = temp_test.pais_residencia.apply(lambda x: pais_mod(x))\n    return temp_train, temp_test\n\n# def modify_pais_residencia(train, test):\n#     temp_train = train.copy()\n#     temp_test = test.copy()\n#     temp_train.pais_residencia = temp_train.pais_residencia.apply(lambda x: mapping_dict['pais_residencia'][x])\n#     temp_test.pais_residencia = temp_test.pais_residencia.apply(lambda x: mapping_dict['pais_residencia'][x])\n#     return temp_train, temp_test\n\ndef canal_mod(x):\n    canal = ['KHE','KAT','KFC','KHQ','KFA','KHK','KHM','KHD','KHN','KAS']\n    if( x not in canal):\n        x = 'UNK'\n    return x\n    \ndef modify_canal_entrada(train, test):\n    temp_train = train.copy()\n    temp_test = test.copy()\n    temp_train.canal_entrada = temp_train.canal_entrada.fillna(temp_train.canal_entrada.mode()[0])\n    temp_test.canal_entrada = temp_test.canal_entrada.fillna(temp_test.canal_entrada.mode()[0])\n    temp_train.canal_entrada = temp_train.canal_entrada.apply(lambda x: canal_mod(x))\n    temp_test.canal_entrada = temp_test.canal_entrada.apply(lambda x: canal_mod(x))\n    return temp_train, temp_test\n\n# def modify_canal_entrada(train, test):\n#     temp_train = train.copy()\n#     temp_test = test.copy()\n#     temp_train.canal_entrada = temp_train.canal_entrada.fillna(temp_train.canal_entrada.mode()[0])\n#     temp_test.canal_entrada = temp_test.canal_entrada.fillna(temp_test.canal_entrada.mode()[0])\n#     temp_train.canal_entrada = temp_train.canal_entrada.apply(lambda x: mapping_dict['canal_entrada'][x])\n#     temp_test.canal_entrada = temp_test.canal_entrada.apply(lambda x: mapping_dict['canal_entrada'][x])\n#     return temp_train, temp_test\n\ndef nom_mod(x):\n    nomprov = ['MADRID','BARCELONA','VALENCIA','SEVILLA','CORUÑA, A','MURCIA','MALAGA','ZARAGOZA','ALICANTE','CADIZ']\n    if x not in nomprov:\n        x = 'OTHER'\n    return x\n\nnom_dict = {\n    'MADRID': 'M',\n    'BARCELONA' : 'B',\n    'VALENCIA' : 'V',\n    'SEVILLA' : 'S',\n    'CORUÑA, A' : 'C',\n    'MURCIA' : 'M1',\n    'MALAGA': 'M2',\n    'ZARAGOZA' : 'Z',\n    'ALICANTE' : 'A1',\n    'CADIZ' : 'C1',\n    'OTHER' : 'O'\n}\ndef modify_nomprov(train, test):\n    temp_train = train.copy()\n    temp_test = test.copy()\n    temp_train.nomprov = temp_train.nomprov.fillna(temp_train.nomprov.mode()[0])\n    temp_test.nomprov = temp_test.nomprov.fillna(temp_test.nomprov.mode()[0])\n    temp_train.nomprov = temp_train.nomprov.apply(lambda x: nom_mod(x))\n    temp_test.nomprov = temp_test.nomprov.apply(lambda x: nom_mod(x))\n    temp_test.nomprov = temp_test.nomprov.apply(lambda x: nom_dict[x])\n    temp_train.nomprov = temp_train.nomprov.apply(lambda x: nom_dict[x])\n    return temp_train, temp_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Memory management Code","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(props, columns_now):\n    start_mem_usg = props.memory_usage().sum() / 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    for col in columns_now:\n        print(col)\n        if props[col].dtype != object:  # Exclude strings\n\n            print(\"******************************\")\n            print(\"dtype before: \",props[col].dtype)\n\n            # make variables for Int, max and min\n            IsInt = False\n            mx = props[col].max()\n            mn = props[col].min()\n\n            # test if column can be converted to an integer\n            asint = props[col].fillna(0).astype(np.int64)\n            result = (props[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n\n\n            # Make Integer/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        props[col] = props[col].astype(np.uint8)\n                    elif mx < 65535:\n                        props[col] = props[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        props[col] = props[col].astype(np.uint32)\n                    else:\n                        props[col] = props[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        props[col] = props[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        props[col] = props[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        props[col] = props[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        props[col] = props[col].astype(np.int64)    \n\n            else:\n                props[col] = props[col].astype(np.float32)\n\n        print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n        mem_usg = props.memory_usage().sum() / 1024**2 \n        print(\"Memory usage is: \",mem_usg,\" MB\")\n        print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n    return props","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataframe Creation","metadata":{}},{"cell_type":"markdown","source":"### Reading CSV","metadata":{}},{"cell_type":"code","source":"# x_train = pd.read_csv(train_file, usecols=feature_cols, parse_dates=['fecha_dato','fecha_alta'])\n# x_test = pd.read_csv(test_file, usecols=feature_cols, parse_dates=['fecha_dato','fecha_alta'])\nx_train = pd.read_csv(train_file, usecols=feature_cols, parse_dates=['fecha_dato'])\nx_test = pd.read_csv(test_file, usecols=feature_cols, parse_dates=['fecha_dato'])\nx_train.fecha_dato = x_train['fecha_dato'].apply(lambda x: 100*x.year + x.month)\nx_test.fecha_dato = x_test['fecha_dato'].apply(lambda x: 100*x.year + x.month)\n# x_train = x_train[((x_train.fecha_dato>=201501) & (x_train.fecha_dato<=201506)) |((x_train.fecha_dato>=201601) & (x_train.fecha_dato<=201604))]# | ((x_train.fecha_dato>=201510)&(x_train.fecha_dato<=201512))]\n# x_train = x_train[x_train.fecha_dato==201604]","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = []\nx_train, x_test = modify_age(x_train, x_test)\ncol_to_drop = []\nfor idx,col in enumerate(x_train.columns):\n    \n    print(\"Reading....\" + str(col))\n\n    if col == 'age' or col == 'fecha_dato':\n        continue\n\n    elif col == \"renta\":\n        x_train, x_test = modify_renta(x_train, x_test)\n        print(col + \"...Done!\")\n\n    elif col == \"segmento\":\n        x_train, x_test = modify_segmento(x_train, x_test)\n        print(col + \"...Done!\")\n\n    elif col == 'sexo':\n        x_train, x_test = modify_sexo(x_train, x_test)\n        print(col + \"...Done!\")\n\n    elif col == \"ind_nuevo\":\n        print(\"Modifying....\"+col)\n        x_train.ind_nuevo = x_train.ind_nuevo.fillna(value=1)\n        x_test.ind_nuevo = x_test.ind_nuevo.fillna(value=1)\n        print(col + \"...Done!\")\n\n    elif col == \"antiguedad\":\n        x_train, x_test = modify_antiguedad(x_train, x_test)\n        print(col + \"...Done!\")\n\n    elif col == 'indrel':\n        print(\"Modifying....\"+col)\n        x_train.indrel = x_train.indrel.fillna(value=1)\n        x_test.indrel = x_test.indrel.fillna(value=1)\n        print(col + \"...Done!\")\n\n    elif col == 'tiprel_1mes':\n        print(\"Modifying....\"+col)\n        x_train.tiprel_1mes = x_train.tiprel_1mes.fillna(x_train.tiprel_1mes.mode()[0])\n        x_train.tiprel_1mes = np.where((x_train.tiprel_1mes=='N')|(x_train.tiprel_1mes=='R'), 'I',x_train.tiprel_1mes)\n        x_test.tiprel_1mes = x_test.tiprel_1mes.fillna(x_test.tiprel_1mes.mode()[0])\n        x_test.tiprel_1mes = np.where((x_test.tiprel_1mes=='N')|(x_test.tiprel_1mes=='R'), 'I',x_test.tiprel_1mes)\n        print(col + \"...Done!\")\n\n    elif col == 'indext':\n        print(\"Modifying....\"+col)\n        x_train.indext = x_train.indext.fillna(value='U')\n        x_test.indext = x_test.indext.fillna(value='U')\n        print(col + \"...Done!\")\n\n    elif col == \"ind_actividad_cliente\":\n        print(\"modifying...\"+col)\n        print(col + \"...Done!\")\n        # No null values\n\n    elif col== 'ncodpers':\n        print(\"Modifying....\"+col)\n        ids = x_test.ncodpers.unique()\n        print(col + \"...Done!\")\n\n    elif col == \"nomprov\":\n        print(\"Modifying....\"+ col)\n        x_train, x_test = modify_nomprov(x_train, x_test)\n        print(col + \"...Done!\")\n\n    elif col == 'fecha_alta':\n        x_train, x_test = modify_fecha_alta(x_train, x_test)\n        print(col + \"...Done!\")\n\n    elif col == 'pais_residencia':\n        print(\"Modifying....\"+ col)\n        x_train, x_test = modify_pais_residencia(x_train, x_test)\n        print(col + \"...Done!\")\n\n    elif col == 'canal_entrada':\n        print(\"Modifying....\"+col)\n        x_train, x_test = modify_canal_entrada(x_train, x_test)\n        print(col + \"...Done!\")\n\n    elif col == 'indrel_1mes':\n        x_train, x_test = modify_indrel_1mes(x_train, x_test)\n        print(col + \"...Done!\")\n\n    else: #Handles indrel, \n        print(\"Modifying....\"+ col)\n        print(col + \"...Done!\")\n\n    '''''''''Null values filled'''''''''''\n    columns_now = []\n\n    if x_train[col].dtype == 'object':\n        x_train[col] = x_train[col].fillna(x_train[col].mode()[0])\n        cat_enc_train = pd.get_dummies(x_train[col], prefix=col)\n        cat_enc_test = pd.get_dummies(x_test[col], prefix=col)\n        for i in cat_enc_train.columns.to_list():\n            columns_now.append(i)\n        x_train = pd.concat([x_train, cat_enc_train], axis=1)\n        x_test = pd.concat([x_test, cat_enc_test], axis=1)\n        col_to_drop.append(col)\n    \n    else:\n        if(col != 'fecha_dato' and col!= 'fecha_alta' and col!='ncodpers'):\n            columns_now.append(col)\n        continue\n        \n    del cat_enc_train, cat_enc_test\n    x_train.select_dtypes(include=['int']).apply(pd.to_numeric,downcast='unsigned')\n    x_train.select_dtypes(include=['float']).apply(pd.to_numeric,downcast='unsigned')\n    x_test.select_dtypes(include=['int']).apply(pd.to_numeric,downcast='unsigned')\n    x_test.select_dtypes(include=['float']).apply(pd.to_numeric,downcast='unsigned')\n    x_train = reduce_mem_usage(x_train, columns_now)\n    print(\"Train Mem reduction...Done!\")\n    x_test = reduce_mem_usage(x_test, columns_now)\n    print(\"Test Mem reduction...Done!\")\n\nfor i in col_to_drop:\n    x_train.drop(columns=[i], inplace=True)\n    x_test.drop(columns=[i], inplace=True)\n    \nprint(x_train.shape)\nprint(x_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = pd.read_csv(train_file, usecols = ['ncodpers','age','fecha_dato','ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1'], dtype=dtype_list, parse_dates=['fecha_dato'])\ny_train.select_dtypes(include=['int']).apply(pd.to_numeric,downcast='unsigned')\ny_train.select_dtypes(include=['float']).apply(pd.to_numeric,downcast='unsigned')\n\n# Selection of rows\ny_train.age = y_train.age.apply(lambda x: string_num_age(x))\ny_train = y_train.loc[y_train.age.isnull()==False]\ny_train.fecha_dato = y_train['fecha_dato'].apply(lambda x: 100*x.year + x.month)\ny_train = y_train.fillna(0)\ny_train.select_dtypes(include=['int']).apply(pd.to_numeric,downcast='unsigned')\ny_train.select_dtypes(include=['float']).apply(pd.to_numeric,downcast='unsigned')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = reduce_mem_usage(y_train,y_train.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lags","metadata":{}},{"cell_type":"code","source":"#Change this function if you take 201501 into consideration \ndef create_lags(lag, date, x_train, df_name):\n    \n    for i in lag:\n        if(i==0):\n            break\n        rename_dict = {}\n        col_names = []\n        for j in targetcols:\n            name = j + '_lag_' + str(i)\n            rename_dict[j] = name\n            col_names.append(name)\n        df = pd.DataFrame()\n        for j in date:\n            cur = j-i\n            if(cur <= 201500):\n                dum = x_train[x_train.fecha_dato == j]\n                df_lag = y_train[y_train.fecha_dato==j]\n                df_lag = df_lag.rename(columns=rename_dict)\n                df_lag.drop(columns=['fecha_dato','age'],inplace=True)\n                for k in col_names:\n                    df_lag[k] = 0\n                dum = dum.merge(df_lag, on=['ncodpers'], how='left')\n                df = pd.concat([df,dum], axis=0)\n                del dum\n            else:\n                if((j > 201600) and cur not in range(201501, 201512) and cur not in range(201601, 201605)):\n                    cur = 201512 - (201600-cur)\n                df_lag = y_train[y_train.fecha_dato==cur]\n                df_lag = df_lag.rename(columns=rename_dict)\n                df_lag.drop(columns=['fecha_dato','age'],inplace=True)\n                dum = x_train[x_train.fecha_dato == j]\n                dum = dum.merge(df_lag, on=['ncodpers'], how='left')\n                df = pd.concat([df,dum], axis=0)\n                print(\"1_>\"+str(j)+\"->\"+str(dum.shape))\n                del dum\n        x_train = df\n        del df\n        print(\"1--->\"+str(x_train.shape))\n        print('Lag '+str(i)+' for ' + df_name +'...Done!!')\n    x_train.fillna(0, inplace=True)\n    return x_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Two way split timeframe","metadata":{}},{"cell_type":"code","source":"'''\n# x_train_complete = reduce_mem_usage(x_train, x_train.columns)\n# x_test_complete = reduce_mem_usage(x_test, x_test.columns)\nlags_1 = [1,2,3,4,5]\nlags_A1 = [1,2,3,4,5]\ndate_A1 = [201506]\ndate_1 = [201604]#[201503,201504,201505,201506]\nlags_2 = [1,2,3]\ndate_2 = [201602,201603,201604]\n\n# x_train_A1 = create_lags(lags_A1, date_A1, x_train, 'x_train_A1')\n# x_train_A1= reduce_mem_usage(x_train_A1, x_train_A1.columns)\n# x_test_A1 = create_lags(lags_A1, [201605], x_test, 'x_test_A1')\n# x_test_A1=reduce_mem_usage(x_test_A1, x_test_A1.columns)\n# y_train_A1 = y_train[((y_train.fecha_dato>=201503) & (y_train.fecha_dato<=201506))]\n# y_train_A1=reduce_mem_usage(y_train_A1, y_train_A1.columns) \n\nx_train_1 = create_lags(lags_1, date_1, x_train, 'x_train_1')\nx_train_1= reduce_mem_usage(x_train_1, x_train_1.columns)\nx_test_1 = create_lags(lags_1, [201605], x_test, 'x_test_1')\nx_test_1=reduce_mem_usage(x_test_1, x_test_1.columns)\ny_train_1 = y_train[((y_train.fecha_dato>=201503) & (y_train.fecha_dato<=201506))]\ny_train_1=reduce_mem_usage(y_train_1, y_train_1.columns) \n\n# x_train_2 = create_lags(lags_2, date_2, x_train, 'x_train_2')\n# x_train_2=reduce_mem_usage(x_train_2, x_train_2.columns)\n# x_test_2 = create_lags(lags_2, [201605], x_test, 'x_test_2')\n# x_test_2=reduce_mem_usage(x_test_2, x_test_2.columns)\n# y_train_2 = y_train[((y_train.fecha_dato>=201602) & (y_train.fecha_dato<=201604))]\n# y_train_2=reduce_mem_usage(y_train_2, y_train_2.columns)\n'''\n\nlags_1 = [1,2,3,4]\ndate_1 = [201503,201504,201505,201506]\nlags_2 = [1,2,3,4,5]\ndate_2 = [201604]\n\nx_train_1 = create_lags(lags_1, date_1, x_train, 'x_train_1')\nx_train_1= reduce_mem_usage(x_train_1, x_train_1.columns)\nx_test_1 = create_lags(lags_1, [201605], x_test, 'x_test_1')\nx_test_1=reduce_mem_usage(x_test_1, x_test_1.columns)\ny_train_1 = y_train[((y_train.fecha_dato>=201503) & (y_train.fecha_dato<=201506))]\ny_train_1=reduce_mem_usage(y_train_1, y_train_1.columns) \n\nx_train_2 = create_lags(lags_2, date_2, x_train, 'x_train_2')\nx_train_2=reduce_mem_usage(x_train_2, x_train_2.columns)\nx_test_2 = create_lags(lags_2, [201605], x_test, 'x_test_2')\nx_test_2=reduce_mem_usage(x_test_2, x_test_2.columns)\ny_train_2 = y_train[((y_train.fecha_dato==201604))]\ny_train_2=reduce_mem_usage(y_train_2, y_train_2.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recent_prod = y_train[y_train.fecha_dato==201604]\n\ndel y_train\ndel x_train, x_test\n\nrecent_prod.drop(columns=['fecha_dato'], inplace=True)\nrecent_prod = reduce_mem_usage(recent_prod, recent_prod.columns)\n\nproduct_col = recent_prod.columns.tolist()\nfor i in ['ncodpers','age']:\n    product_col.remove(i)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model \n### Weighted Average LGBM ","metadata":{}},{"cell_type":"code","source":"# import lightgbm as lgb\n# from collections import defaultdict\n# import joblib\n\n# params = {'boosting_type': 'gbdt',\n#           'max_depth' : -1,\n#           'objective': 'binary',\n#           'num_leaves': 64,\n#           'learning_rate': 0.1,\n#           'num_iterations': 200,\n#           'max_bin': 512,\n#           'subsample_for_bin': 200,\n#           'subsample': 1,\n#           'subsample_freq': 1,\n#           'colsample_bytree': 0.8,\n#           'reg_alpha': 5,\n#           'reg_lambda': 10,\n#           'min_split_gain': 0.5,\n#           'min_child_weight': 1,\n#           'min_child_samples': 5,\n#           'scale_pos_weight': 1,\n#           'num_class' : 1,\n#           'metric' : 'binary_error',\n#          'verbosity' : 1}\n\n# id_preds = defaultdict(list)\n# ids = x_test_1['ncodpers'].values\n# models = {}\n\n# for c in product_col:\n#     print(c)\n#     print(c+\"-first\")\n#     y_t_1 = y_train_1[c]\n#     x_t_1 = x_train_1.drop(['fecha_dato','ncodpers'],1)\n#     model_1 = lgb.LGBMClassifier(\n#         boosting_type= 'gbdt',\n#         objective = 'binary',\n#         #n_jobs = 3, # Updated from 'nthread'\n#         #silent = True,\n#         max_depth = params['max_depth'],\n#         max_bin = params['max_bin'],\n#         #subsample_for_bin = params['subsample_for_bin'],\n#         subsample = params['subsample'],\n#         subsample_freq = params['subsample_freq'],\n#         min_split_gain = params['min_split_gain'],\n#         min_child_weight = params['min_child_weight'],\n#         min_child_samples = params['min_child_samples'],\n#         scale_pos_weight = params['scale_pos_weight'],\n#         learning_rate=params['learning_rate'],\n#         num_iterations=params['num_iterations'],\n#         verbosity = params['verbosity']\n#     )\n    \n#     model_1.fit(x_t_1,y_t_1)\n#     x_t2_1 = x_test_1.drop(['fecha_dato','ncodpers'],1)\n#     prediction_1 = model_1.predict_proba(x_t2_1)[:,1]\n#     name = './'+c+'2015.pkl'\n#     joblib.dump(model_1, name)\n#     models[c] = model_1\n#     del x_t_1, y_t_1, x_t2_1, model_1\n\n#     for id, p in zip(ids, prediction_1):\n#         id_preds[id].append(p)\n\n# joblib.dump(models,'./combined2015.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\nimport joblib\n\nid_preds = defaultdict(list)\nids = x_test_1['ncodpers'].values\n\nmodel_15 = joblib.load('../input/combined2015/combined2015.pkl')\nmodel_16 = joblib.load('../input/combined2016/combined.pkl')\nfor c in product_col:\n    print(c)\n    x_t2_1 = x_test_1.drop(['fecha_dato','ncodpers'],1)\n    model_1 = model_15[c]\n    prediction_1 = model_1.predict_proba(x_t2_1)[:,1]\n    \n    x_t2_2 = x_test_2.drop(['fecha_dato','ncodpers'],1)\n    model_2 = model_16[c]\n    prediction_2 = model_2.predict_proba(x_t2_2)[:,1]\n    \n    prediction = prediction_1*0.2 + prediction_2*0.8\n    for id, p in zip(ids, prediction):\n        id_preds[id].append(p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Final Prediction Selection","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n#id_preds.items()\ntrain_preds = {}\n\nfor id, p in tqdm(id_preds.items(), desc='Loading....'):\n    try:\n        recent = recent_prod[recent_prod.ncodpers==id].iloc[0]\n        preds = {}\n        for i in zip(tuple(product_col),p):\n            if(recent[i[0]] == 1):\n                preds[i[0]] = 1 - i[1]\n            else:\n                preds[i[0]] = i[1]\n\n        temp_fin = sorted(preds.items(), key = lambda x: x[1], reverse=True)[:5]  #Dict\n        preds_fin = []\n        for i in temp_fin:\n            preds_fin.append(i[0])\n        train_preds[id] = preds_fin\n    except:\n        #Guy is new\n        for i in zip(tuple(product_col),p):\n            preds[i[0]] = i[1]\n        temp_fin = sorted(preds.items(), key = lambda x: x[1], reverse=True)[:5]\n        preds_fin = []\n        for i in temp_fin:\n            preds_fin.append(i[0])\n        train_preds[id] = preds_fin\n\ndf = {\n    'ncodpers': [],\n    'changed' : []\n}\nfor i in train_preds:\n    df['ncodpers'].append(i)\n    prods = ''\n    for j in train_preds[i]:\n        prods += \" \" + j\n    df['changed'].append(prods)\n\nprint(df)\nfinal_df = pd.DataFrame(df, columns = ['ncodpers','changed'])\nfinal_df.to_csv('/kaggle/working/lgbm_sub1.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}